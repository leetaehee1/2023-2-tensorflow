# <p align="center"> KOELECTRA를 활용한 스팀 게임 리뷰 감성 분석 </p>
<p align="center"><img src="https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/95b2d3fe-9bc0-4584-8b5f-47b3995bfe27" width="750px" height="380px"></p>  

# 1. 개요
이번 프로젝트에서는 한국어 자연어 처리 모델인 [KOELECTRA](https://github.com/monologg/KoELECTRA)를 활용하여 **[스팀](https://namu.wiki/w/Steam)** 게임 리뷰의 긍부정 예측을 하고자 한다.  

## 1.1 문제 정의

**게임 리뷰**는 비디오 게임에 대한 평가, 분석, 및 의견을 담은 글, 비디오, 오디오, 또는 다른 형태의 콘텐츠이다. 
이러한 게임 리뷰는 게임 소비자에게 게임의 내용과 질에 대한 정보를 제공하며, 이를 통해 소비자는 자신의 관심사와 기대치에 부합하는 게임을 선택할 수 있다. 또한, 다른 게임과 비교하여 그들의 취향과 목적을 가장 잘 충족시킬지 비교하여 선택하는데 도움을 준다.

이런 게임 리뷰를 통해 사람들은 리뷰를 읽고 게임의 내용과 품질을 평가한 후 게임을 구매할지 여부를 결정하거나, 재미요소, 게임플레이, 스토리, 그래픽 품질 등을 파악하고 잘 작성된 리뷰를 통해 잘못 선택한 게임으로 인한 시간과 자원의 낭비를 피하고 **자신이 즐길만한 만족스러운 게임**을 선택할 수 있다.

이로 인해 게임 리뷰는 게임 커뮤니티와 산업에 중요한 역할을 하며, 게임 소비자와 게임 개발자 간의 상호작용은 게임의 품질 향상과 그들의 작품을 개선하고 발전시키는데 도움을 준다.[[1]](https://s-space.snu.ac.kr/handle/10371/166332)




<!-- - 게임 리뷰와 게임 흥행의 상관관계를 나타내는 참고자료를 통해 게임 리뷰의 가치를 언급
 - [[1]](링크) 등의 표기를 문장 뒤에 활용하여 참고 문헌을 작성할 것
 - 프로젝트로 해당 과업을 해결할 때 기대할 수 있는 장점, 활용 가능성 등을 언급
 - 필요에 따라서는 적절한 그림을 그려 표현(ppt 등) -->

## 1.2 데이터 및 모델 개요
데이터는 **bab2min**의 Github - corpus 에서 공유하는 [스팀 게임 리뷰](https://github.com/bab2min/corpus/tree/master/sentiment)를 활용[2]하여, 총 10만 건의 데이터에 대해서 사전 학습 언어 모델의 재학습(fine-tuning)을 수행한다.   
게임 유통 서비스인 Steam의 각종 게임에 달린 한국어 리뷰를 수집한 것이다. 게임 커뮤니티 특성 상 비속어 및 은어가 많이 사용된 것이 특징이다. 데이터는 탭으로 분리되어 있으며, 첫번째 필드에는 긍/부정(1=긍정, 0=부정), 두번째 필드에는 리뷰 텍스트가 위치한다. 긍정과 부정의 비율이 1:1에 가깝도록 샘플링된 자료이다.

 - 언어: 한국어
 - 출처: Steam (https://store.steampowered.com/)
 - 수집 기간: 2020.05~2020.06
### 데이터 분포

| |건수|
|---|---|
|긍정|49,996|
|부정|50,004|
|합계|100,000|

## 1.3 데이터 미리보기

| 입력          |모델|출력|
|-------------|---|---|
| 스팀 게임 리뷰 문장|[KOELECTRA small](https://github.com/monologg/KoELECTRA) [3]|부정(0), 긍정(1) |

# 2. 데이터
## 감성 분석 순서  
![634](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/4837a454-600b-4542-a845-4f29be85674b)

## 2.1 데이터 소스

| 입력          |출력|
|-------------|---|
| 스팀 게임 리뷰 문장|부정(0), 긍정(1) |
|노래가 너무 적음|0|
|돌겠네 진짜. 황숙아, 어크 공장 그만 돌려라. 죽는다.|0|
|막노동 체험판 막노동 하는사람인데 장비를 내가 사야돼 뭐지|1|
|차악!차악!!차악!!! 정말 이래서 왕국을 되찾을 수 있는거야??|1|
|...|...|
|     노잼이네요... 30분하고 지웠어요...|0|
| 야생을 사랑하는 사람들을 위한 짧지만 여운이 남는 이야기. 영어는 그리 어렵지 않습니다.|1|
 |                 한국의 메탈레이지를 떠오르게한다 진짜 손맛으로 하는게임|1|

## 2.2 탐색적 데이터 분석
- **label** 분류 및 시각화
  |label||
  |---|---|
  |0|49,957|
  |1|49,936|
  
  ![Figure_1](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/471992fb-6f27-4f90-af89-82b791d9b396)    
  라벨을 분류하고 시각화를 해봤을때 0(부정) 49,957, 1(긍정) 49,936개로 적당하게 절반 나뉘어져 있다.

 - 전체 데이터의 문장길이 분포 확인
   
   ![문장길이의분포](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/7fecdf0c-71d4-4122-aec7-e7bf8518021d)   
   문장의 최소 길이인 1부터 시작해서 5씩 늘려가며 분포를 나타내 1부터 6까지 약 35,000개, 6부터 11까지 약 25,000개, ... 로 문장 길이의 분포를 나타냈다.

## 2.3 데이터 전처리
- 입력 데이터의 전처리 과정
  steam.txt 파일의 데이터를 읽어 처리한 후 동일한 파일에 탭으로 구분된 형식으로 저장함.
  
- 전체 데이터의 양
  ```
  print("데이터의 개수 : ", len(data))
  ```
  ![data_size](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/38f37b78-12bd-42f5-aeb4-09d8bd444eaa)   
  전체 데이터의 양은 총 100,000개가 있다.
  
- 데이터 중복, 결측치 제거
  ```
  data.drop_duplicates(subset=['document'], inplace=True)
  print("데이터의 개수 (중복제거): ", len(data))
  
  print(data.isnull().values.any()) # 결측치 (Null, NaN)가 있다면 True
  data = data.dropna(how='any')
  print("데이터의 개수 (결측치 제거): ", len(data))
  print()
  ```
  ![del_nullandDupl](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/1300b005-3fa6-41ca-ad31-ca720d1583b9)   
  서로 다른 데이터의 개수는 99,893개이고, 중복과 결측치를 제거한 결과도 동일하게 99,893개이다.
  
### 데이터 10,000개 추출   
- 총 10만개의 데이터 중 학습할 데이터 1만개 추출
  ```
  import random

  import pandas as pd
  
  data = pd.read_table('steam.txt')
  print(data)
  
  # 데이터프레임의 행 수를 가져옵니다
  num_rows = len(data)
  
  # 1만개의 무작위 행 인덱스를 생성
  random_indices = random.sample(range(num_rows), 10000)
  
  # 무작위로 선택된 행을 추출
  random_sample = data.iloc[random_indices]
  
  # 인덱스를 오름차순으로 정렬
  random_sample = random_sample.sort_index(ascending=True)
  print(random_sample)
  
  random_sample.to_csv('steam_10000.txt', sep='\t', index=False)
  ```

- 데이터 확인  
  <!-- ![data_10000](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/62daf4f8-21df-4dee-aa2c-77d86a95ac02) -->

  |학습 데이터의 수|10000|
  |---|---|
  |긍정 리뷰 수|4,991|
  |부정 리뷰 수|5,009|
  
  무작위로 10,000개 추출했을때 약 5:5 비율로 적당하게 나뉘어져 추출된 것을 볼 수 있다.

- 학습과 검증 데이터셋 분리    
  <!-- ![데이터셋분리](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/dc9625fb-78ea-4812-b2d8-fdf27f063df7) -->

  |데이터 분리||
  |---|---|
  |학습 데이터 수|8,000|
  |검증 데이터 수|2,000|
  
  위에서 언급한 학습 데이터 10,000개에서 학습 데이터를 8,000개, 검증 데이터를 2,000개로 분리했다.
  
- 학습 데이터의 구성  
  |Document|Label|
  |---|---|
  |                                            노래가 너무 적음|    0|
  |                     돌겠네 진짜. 황숙아, 어크 공장 그만 돌려라. 죽는다.|    0|
  |                    막노동 체험판 막노동 하는사람인데 장비를 내가 사야돼 뭐지|    1|
  |                차악!차악!!차악!!! 정말 이래서 왕국을 되찾을 수 있는거야??|    1|
  |                 시간 때우기에 좋음.. 도전과제는 50시간이면 다 깰 수 있어요|    1|

### 데이터 1,000개 추출

- 데이터 확인   
   |학습 데이터 수|1,000|
   |---|---|
   |긍정 리뷰 수|495|
   |부정 리뷰 수|505|

    무작위로 1,000개 추출했을때 약 5:5 비율로 적당하게 나뉘어져 추출된 것을 볼 수 있다.

- 학습과 검증 데이터셋 분리
   
  |데이터 분리||
  |---|---|
  |학습 데이터 수|800|
  |검증 데이터 수|200|
  
  위에서 언급한 학습 데이터 1,000개에서 학습 데이터를 800개, 검증 데이터를 200개로 분리했다.
  
- 학습 데이터의 구성   
   |Label|Document|
   |---|---|
   |1|트레이아크 사랑해요 핰핰|
   |1|난이도가 너무너무 높다 ...|
   |1|200시간이면 평가해도돼요? ...|
   |0|저의 인생최대의 실수 중하나는 이게임을다운받고플레이했다는겁니다 ㅎ;;|
   |0|마이! 퍽킹! 머니!!!!|
  
  <!-- ![1000all](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/16bdf420-88ef-4062-abf8-098afa500659) -->   


# 3. 재학습 결과
- 10,000건 추출한 데이터 검증 정확도

```
  평균 학습 오차(loss) : 0.6088948954343796
  학습에 걸린 시간 : 1:52:45
  
  
  ** 검증 **
  검증 정확도 : 0.6969246031746031
```

무작위 10,000건의 데이터를 추출한 후 검증 결과 정확도가 69.7%로 낮게 나타났다. 이는 데이터에 오류나 편향이 존재할 가능성이 있음을 시사한다.
  
- 1,000건 추출한 데이터 검증 정확도
```
  평균 학습 오차(loss) : 0.4590940597729805
  학습에 걸린 시간 : 0:15:41
  
  
  ** 검증 **
  검증 정확도 : 0.687202380952381
```

마찬가지로 1,000건의 데이터를 다시 추출한 후 검증 결과도 정확도가 68.7%로 낮게 나타났다. 이 또한 데이터의 상태가 좋지 않다는 것을 확인할 수 있는 근거가 된다.

## 3.1 학습 결과 그래프

### 10,000건 추출한 데이터
|평균 학습 오차율(loss)|검증 정확도|
|---|---|
![111](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/8a99692d-b485-4dd6-b373-574e24abbafb) | ![222](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/580a16ba-f097-4dee-9a72-006e04f43e21)

무작위 데이터 1만건을 추출한 후 5 epoch을 학습한 결과, 평균 학습 오차율은 0.6685에서 0.6089로 감소했다. 이는 학습이 진행됨에 따라 모델이 데이터에 잘 맞추어지고 있음을 의미한다.   
검증 정확도는 63.0%에서 60.0%으로 감소한 후 69.7%로 증가했다. 이는 학습 초기에는 모델이 학습 데이터에 너무 과도하게 적응하여 과적합이 발생하였으나, 이후 학습이 진행됨에 따라 과적합이 완화되면서 실제 데이터에 대한 성능이 향상되었음을 의미한다.   
하지만 그래도 나머지 30%의 데이터에 대해서는 모델이 잘 예측하지 못하고 있다는 점을 의미해 모델의 성능이 좋다 할 수 없다.

### 1,000건 추출한 데이터
|평균 학습 오차율(loss)|검증 정확도|
|---|---|
![1](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/fb4fe491-a63a-4433-add5-d884a5644feb) |![화면 캡처 2023-12-09 000226](https://github.com/leetaehee1/Koelectra_SteamReview/assets/79897716/f8db9c0a-0a97-4668-b8e8-3c9e3c47a60e)

위에와 마찬가지로 평균 학습 오차율이 0.7에서 0.46까지 감소하는 것은 학습이 진행됨에 따라 모델이 데이터에 잘 맞추어지고 있다는 것을 의미한다. 그러나 검증 정확도가 47%에서 68.7%까지 올라가는 것만으로는 모델의 성능이 충분히 개선되었다고 보기 어렵다. 그 이유는 검증 정확도는 모델이 테스터 데이터에 대해 얼마나 잘 수행할 수 있는지를 나타내는 지표인데, 검증 정확도가 68.7%까지 올라갔다고 하더라도 30%의 데이터에 대해서는 모델이 잘 예측하지 못하고 있다는 점을 의미해 모델의 성능이 좋다 할 수 없다.

# 4. 소결

무작위 10,000건과 1,000건의 데이터를 추출하여 검증한 결과, 두 경우 모두 정확도가 60%대에서 70%대에 머무르는 것으로 나타났다. 이는 데이터에 오류나 편향이 존재할 가능성이 있음을 시사한다.
학습 결과 그래프를 살펴보면, 평균 학습 오차율은 두 경우 모두 학습이 진행됨에 따라 감소하는 추세를 보였다. 이는 학습이 진행됨에 따라 모델이 데이터에 잘 맞추어지고 있음을 의미한다.
그러나 검증 정확도는 학습 초기에는 감소했다가 이후 증가하는 추세를 보였다. 이는 학습 초기에는 모델이 학습 데이터에 너무 과도하게 적응하여 과적합이 발생하였으나, 이후 학습이 진행됨에 따라 과적합이 완화되면서 실제 데이터에 대한 성능이 향상되었음을 의미한다.
그러나 그래도 나머지 30%의 데이터에 대해서는 모델이 잘 예측하지 못하고 있다는 점을 의미해 모델의 성능이 좋다 할 수 없다.
결론적으로, 데이터에 오류나 편향이 존재할 가능성이 있으므로, 데이터를 정제하거나 보완하는 등의 작업을 통해 데이터의 상태를 개선할 필요가 있다. 또한, 모델의 복잡도를 조절하거나, 정규화 기법을 적용하는 등의 방법을 통해 과적합을 방지할 필요가 있다.

마지막으로 데이터의 상태를 개선하기 위해서는 데이터의 오류를 수정하거나, 편향을 완화, 다양성을 높이는 등의 방법을 고려해볼 수 있고, 과적합을 방지하기 위해서는 모델의 복잡도를 조절하고, 정규화 기법(normalize)를 적용하거나, 데이터 증강을 적용하는 등의 방법도 고려해 볼 수 있을것 같다. 

# 5. 결론 

데이터 검증 결과 10,000건과 1,000건의 데이터를 무작위로 추출하여 검증한 결과, 정확도가 60%대에서 70%대에 머무르는 것으로 나타났다. 이는 데이터에 오류나 편향이 존재할 가능성이 있음을 시사한다.   
데이터의 상태를 개선하고 과적합을 방지하기 위한 방법을 고려하여 모델의 성능을 향상시킬 필요가 있다.

이번 프로젝트를 진행하면서 데이터의 상태의 중요성을 이해하게 되었다. 데이터의 상태가 모델의 성능을 결정하는데, 상태가 좋지 않으면 모델이 데이터에 잘 맞추어질수 없어 성능이 저하될 수 있기 때문이다. 따라서 데이터의 상태를 개선하는것은 모델의 성능을 향상시키는데 중요한 요소라는 것을 배우게 되었다.

--------------------------------------------------
#### 개발 환경
 - pycharm, [requirements.txt](https://github.com/leetaehee1/Koelectra_SteamReview/blob/main/requirements.txt)
## 참고문헌
steam 이미지 : https://cdn.cloudflare.steamstatic.com/store/home/store_home_share.jpg  
[1] 리뷰가 비디오 게임의 성과에 미치는 영향 : https://s-space.snu.ac.kr/handle/10371/166332  
[2] Github / bab2min - corpus의 Steam.txt 자료 : https://github.com/bab2min/corpus/tree/master/sentiment  
[3] Koelectra 모델에 대한 참고문헌 : https://github.com/monologg/KoELECTRA
